{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-23T20:00:52.337991Z",
     "start_time": "2023-04-23T20:00:51.983274Z"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-23T20:00:58.959453Z",
     "start_time": "2023-04-23T20:00:52.325516Z"
    }
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('Basics').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-23T20:01:04.409913Z",
     "start_time": "2023-04-23T20:00:58.959453Z"
    }
   },
   "outputs": [],
   "source": [
    "df_pyspark = spark.read.csv('test1.csv', inferSchema=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-23T20:01:04.429090Z",
     "start_time": "2023-04-23T20:01:04.410915Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Name: string (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- Experience: integer (nullable = true)\n",
      " |-- Salary: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-23T20:01:04.722703Z",
     "start_time": "2023-04-23T20:01:04.426086Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "|age|\n",
      "+---+\n",
      "| 31|\n",
      "| 30|\n",
      "| 29|\n",
      "| 24|\n",
      "| 21|\n",
      "| 23|\n",
      "+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.select('age').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-23T20:01:04.796285Z",
     "start_time": "2023-04-23T20:01:04.726080Z"
    }
   },
   "outputs": [],
   "source": [
    "df_pyspark = df_pyspark.withColumn(\"Experience after 10 years\", df_pyspark['experience']+10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-23T20:01:05.065701Z",
     "start_time": "2023-04-23T20:01:04.772993Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+----------+------+-------------------------+\n",
      "|     Name|age|Experience|Salary|Experience after 10 years|\n",
      "+---------+---+----------+------+-------------------------+\n",
      "|    Krish| 31|        10| 30000|                       20|\n",
      "|Sudhanshu| 30|         8| 25000|                       18|\n",
      "|    Sunny| 29|         4| 20000|                       14|\n",
      "|     Paul| 24|         3| 20000|                       13|\n",
      "|   Harsha| 21|         1| 15000|                       11|\n",
      "|  Shubham| 23|         2| 18000|                       12|\n",
      "+---------+---+----------+------+-------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-23T20:01:05.139257Z",
     "start_time": "2023-04-23T20:01:05.065701Z"
    }
   },
   "outputs": [],
   "source": [
    "df_pyspark = df_pyspark.drop('Experience after 10 years')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-23T20:01:05.314477Z",
     "start_time": "2023-04-23T20:01:05.083506Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+----------+------+\n",
      "|     Name|age|Experience|Salary|\n",
      "+---------+---+----------+------+\n",
      "|    Krish| 31|        10| 30000|\n",
      "|Sudhanshu| 30|         8| 25000|\n",
      "|    Sunny| 29|         4| 20000|\n",
      "|     Paul| 24|         3| 20000|\n",
      "|   Harsha| 21|         1| 15000|\n",
      "|  Shubham| 23|         2| 18000|\n",
      "+---------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-23T20:01:05.333863Z",
     "start_time": "2023-04-23T20:01:05.301444Z"
    }
   },
   "outputs": [],
   "source": [
    "df_pyspark =df_pyspark.withColumnRenamed('experience', 'experience after 10 years')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-23T20:01:05.486972Z",
     "start_time": "2023-04-23T20:01:05.317856Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+-------------------------+------+\n",
      "|     Name|age|experience after 10 years|Salary|\n",
      "+---------+---+-------------------------+------+\n",
      "|    Krish| 31|                       10| 30000|\n",
      "|Sudhanshu| 30|                        8| 25000|\n",
      "|    Sunny| 29|                        4| 20000|\n",
      "|     Paul| 24|                        3| 20000|\n",
      "|   Harsha| 21|                        1| 15000|\n",
      "|  Shubham| 23|                        2| 18000|\n",
      "+---------+---+-------------------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-23T20:01:05.866986Z",
     "start_time": "2023-04-23T20:01:05.476601Z"
    }
   },
   "outputs": [],
   "source": [
    "df_pyspark = spark.read.csv('test2.csv', inferSchema=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-23T20:01:06.040283Z",
     "start_time": "2023-04-23T20:01:05.854984Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----+----------+------+\n",
      "|     Name| age|Experience|Salary|\n",
      "+---------+----+----------+------+\n",
      "|    Krish|  31|        10| 30000|\n",
      "|Sudhanshu|  30|         8| 25000|\n",
      "|    Sunny|  29|         4| 20000|\n",
      "|     Paul|  24|         3| 20000|\n",
      "|   Harsha|  21|         1| 15000|\n",
      "|  Shubham|  23|         2| 18000|\n",
      "|   Mahesh|null|      null| 40000|\n",
      "|     null|  34|        10| 38000|\n",
      "|     null|  36|      null|  null|\n",
      "+---------+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-23T20:01:06.206313Z",
     "start_time": "2023-04-23T20:01:06.041784Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----+----------+------+\n",
      "|     Name| age|Experience|Salary|\n",
      "+---------+----+----------+------+\n",
      "|    Krish|  31|        10| 30000|\n",
      "|Sudhanshu|  30|         8| 25000|\n",
      "|    Sunny|  29|         4| 20000|\n",
      "|     Paul|  24|         3| 20000|\n",
      "|   Harsha|  21|         1| 15000|\n",
      "|  Shubham|  23|         2| 18000|\n",
      "|   Mahesh|null|      null| 40000|\n",
      "|     null|  34|        10| 38000|\n",
      "+---------+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.na.drop(how='any', thresh=2).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-23T20:01:06.335528Z",
     "start_time": "2023-04-23T20:01:06.196491Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----+----------+------+\n",
      "|     Name| age|Experience|Salary|\n",
      "+---------+----+----------+------+\n",
      "|    Krish|  31|        10| 30000|\n",
      "|Sudhanshu|  30|         8| 25000|\n",
      "|    Sunny|  29|         4| 20000|\n",
      "|     Paul|  24|         3| 20000|\n",
      "|   Harsha|  21|         1| 15000|\n",
      "|  Shubham|  23|         2| 18000|\n",
      "|   Mahesh|null|      null| 40000|\n",
      "|     null|  34|        10| 38000|\n",
      "+---------+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.na.drop(how='any', subset=['Salary']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-23T20:01:06.897756Z",
     "start_time": "2023-04-23T20:01:06.336532Z"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Imputer\n",
    "\n",
    "imputer = Imputer(\n",
    "    inputCols = ['age', 'Experience', 'Salary'],\n",
    "    outputCols = [\"{}_imputed\".format(a) for a in ['Age of Employee', 'Experience (in years)', 'Salary (per month - $)']]\n",
    ").setStrategy(\"mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-23T20:01:07.676882Z",
     "start_time": "2023-04-23T20:01:06.898756Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----+----------+------+-----------------------+-----------------------------+------------------------------+\n",
      "|     Name| age|Experience|Salary|Age of Employee_imputed|Experience (in years)_imputed|Salary (per month - $)_imputed|\n",
      "+---------+----+----------+------+-----------------------+-----------------------------+------------------------------+\n",
      "|    Krish|  31|        10| 30000|                     31|                           10|                         30000|\n",
      "|Sudhanshu|  30|         8| 25000|                     30|                            8|                         25000|\n",
      "|    Sunny|  29|         4| 20000|                     29|                            4|                         20000|\n",
      "|     Paul|  24|         3| 20000|                     24|                            3|                         20000|\n",
      "|   Harsha|  21|         1| 15000|                     21|                            1|                         15000|\n",
      "|  Shubham|  23|         2| 18000|                     23|                            2|                         18000|\n",
      "|   Mahesh|null|      null| 40000|                     28|                            5|                         40000|\n",
      "|     null|  34|        10| 38000|                     34|                           10|                         38000|\n",
      "|     null|  36|      null|  null|                     36|                            5|                         25750|\n",
      "+---------+----+----------+------+-----------------------+-----------------------------+------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "imputer.fit(df_pyspark).transform(df_pyspark).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-23T20:01:07.879990Z",
     "start_time": "2023-04-23T20:01:07.680418Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "df_pyspark = spark.read.csv('test1.csv', inferSchema=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-23T20:01:07.974651Z",
     "start_time": "2023-04-23T20:01:07.881205Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+----------+------+\n",
      "|     Name|age|Experience|Salary|\n",
      "+---------+---+----------+------+\n",
      "|    Krish| 31|        10| 30000|\n",
      "|Sudhanshu| 30|         8| 25000|\n",
      "|    Sunny| 29|         4| 20000|\n",
      "|     Paul| 24|         3| 20000|\n",
      "|   Harsha| 21|         1| 15000|\n",
      "|  Shubham| 23|         2| 18000|\n",
      "+---------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-23T20:01:08.151292Z",
     "start_time": "2023-04-23T20:01:07.974651Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+\n",
      "|   name|salary|\n",
      "+-------+------+\n",
      "|  Sunny| 20000|\n",
      "|   Paul| 20000|\n",
      "| Harsha| 15000|\n",
      "|Shubham| 18000|\n",
      "+-------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.filter(\"Salary<=20000\").select(['name', 'salary']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-23T20:01:08.279609Z",
     "start_time": "2023-04-23T20:01:08.144489Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+\n",
      "|     name|salary|\n",
      "+---------+------+\n",
      "|    Krish| 30000|\n",
      "|Sudhanshu| 25000|\n",
      "+---------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.filter(~(df_pyspark['Salary']<=20000)).select(['name', 'salary']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-23T20:01:08.501474Z",
     "start_time": "2023-04-23T20:01:08.269592Z"
    }
   },
   "outputs": [],
   "source": [
    "df_pyspark = spark.read.csv('test3.csv', inferSchema=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-23T20:01:08.624994Z",
     "start_time": "2023-04-23T20:01:08.501474Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------+------+\n",
      "|     Name| Departments|salary|\n",
      "+---------+------------+------+\n",
      "|    Krish|Data Science| 10000|\n",
      "|    Krish|         IOT|  5000|\n",
      "|   Mahesh|    Big Data|  4000|\n",
      "|    Krish|    Big Data|  4000|\n",
      "|   Mahesh|Data Science|  3000|\n",
      "|Sudhanshu|Data Science| 20000|\n",
      "|Sudhanshu|         IOT| 10000|\n",
      "|Sudhanshu|    Big Data|  5000|\n",
      "|    Sunny|Data Science| 10000|\n",
      "|    Sunny|    Big Data|  2000|\n",
      "+---------+------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-23T20:01:08.988317Z",
     "start_time": "2023-04-23T20:01:08.627359Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------+\n",
      "|salary|avg(salary)|\n",
      "+------+-----------+\n",
      "|  3000|     3000.0|\n",
      "|  4000|     4000.0|\n",
      "|  5000|     5000.0|\n",
      "| 10000|    10000.0|\n",
      "| 20000|    20000.0|\n",
      "|  2000|     2000.0|\n",
      "+------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.groupBy('salary').mean().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-23T20:01:09.271186Z",
     "start_time": "2023-04-23T20:01:08.988317Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|salary|count|\n",
      "+------+-----+\n",
      "|  3000|    1|\n",
      "|  4000|    2|\n",
      "|  5000|    2|\n",
      "| 10000|    3|\n",
      "| 20000|    1|\n",
      "|  2000|    1|\n",
      "+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.groupBy('salary').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-23T20:01:09.519067Z",
     "start_time": "2023-04-23T20:01:09.268897Z"
    }
   },
   "outputs": [],
   "source": [
    "training = spark.read.csv('test1.csv', inferSchema=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-23T20:01:09.581772Z",
     "start_time": "2023-04-23T20:01:09.520089Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+----------+------+\n",
      "|     Name|age|Experience|Salary|\n",
      "+---------+---+----------+------+\n",
      "|    Krish| 31|        10| 30000|\n",
      "|Sudhanshu| 30|         8| 25000|\n",
      "|    Sunny| 29|         4| 20000|\n",
      "|     Paul| 24|         3| 20000|\n",
      "|   Harsha| 21|         1| 15000|\n",
      "|  Shubham| 23|         2| 18000|\n",
      "+---------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "training.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-23T20:01:09.597375Z",
     "start_time": "2023-04-23T20:01:09.581772Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Name', 'age', 'Experience', 'Salary']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-23T20:01:09.655690Z",
     "start_time": "2023-04-23T20:01:09.597375Z"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-23T20:01:09.673878Z",
     "start_time": "2023-04-23T20:01:09.613458Z"
    }
   },
   "outputs": [],
   "source": [
    "featureassembler = VectorAssembler(inputCols=['age', 'Experience'], outputCol='Independent Features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-23T20:01:09.782346Z",
     "start_time": "2023-04-23T20:01:09.643600Z"
    }
   },
   "outputs": [],
   "source": [
    "output = featureassembler.transform(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-23T20:01:10.047161Z",
     "start_time": "2023-04-23T20:01:09.784901Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+----------+------+--------------------+\n",
      "|     Name|age|Experience|Salary|Independent Features|\n",
      "+---------+---+----------+------+--------------------+\n",
      "|    Krish| 31|        10| 30000|         [31.0,10.0]|\n",
      "|Sudhanshu| 30|         8| 25000|          [30.0,8.0]|\n",
      "|    Sunny| 29|         4| 20000|          [29.0,4.0]|\n",
      "|     Paul| 24|         3| 20000|          [24.0,3.0]|\n",
      "|   Harsha| 21|         1| 15000|          [21.0,1.0]|\n",
      "|  Shubham| 23|         2| 18000|          [23.0,2.0]|\n",
      "+---------+---+----------+------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "output.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-23T20:01:10.105812Z",
     "start_time": "2023-04-23T20:01:10.047161Z"
    }
   },
   "outputs": [],
   "source": [
    "finalized_data = output.select('Independent Features', 'Salary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-23T20:01:10.184096Z",
     "start_time": "2023-04-23T20:01:10.063689Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+\n",
      "|Independent Features|Salary|\n",
      "+--------------------+------+\n",
      "|         [31.0,10.0]| 30000|\n",
      "|          [30.0,8.0]| 25000|\n",
      "|          [29.0,4.0]| 20000|\n",
      "|          [24.0,3.0]| 20000|\n",
      "|          [21.0,1.0]| 15000|\n",
      "|          [23.0,2.0]| 18000|\n",
      "+--------------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "finalized_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-23T20:01:10.960392Z",
     "start_time": "2023-04-23T20:01:10.143293Z"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "train_data, test_data = finalized_data.randomSplit([0.75, 0.25])\n",
    "regressor = LinearRegression(featuresCol='Independent Features', labelCol='Salary')\n",
    "regressor = regressor.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-23T20:01:11.025374Z",
     "start_time": "2023-04-23T20:01:10.953230Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseVector([-357.1429, 1785.7143])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-23T20:01:11.038801Z",
     "start_time": "2023-04-23T20:01:10.999587Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23214.285714287067"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-23T20:01:11.171953Z",
     "start_time": "2023-04-23T20:01:11.014550Z"
    }
   },
   "outputs": [],
   "source": [
    "pred_results = regressor.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-23T20:01:11.316982Z",
     "start_time": "2023-04-23T20:01:11.173162Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+------------------+\n",
      "|Independent Features|Salary|        prediction|\n",
      "+--------------------+------+------------------+\n",
      "|          [21.0,1.0]| 15000|17500.000000000196|\n",
      "|          [23.0,2.0]| 18000|  18571.4285714287|\n",
      "|          [30.0,8.0]| 25000|26785.714285714275|\n",
      "+--------------------+------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_results.predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-23T20:01:11.326318Z",
     "start_time": "2023-04-23T20:01:11.308918Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
